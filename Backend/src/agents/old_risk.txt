from typing import Dict, Any, Tuple, List
from src.agents.base_agent import BaseAgent
from src.data.models import OutcomeType
from src.workflow.state import AlertInvestigationState
import json
import uuid
from datetime import datetime

class RiskAssessmentAgent(BaseAgent):
    def __init__(self, db_manager, llm_helper, config):
        super().__init__(db_manager, llm_helper, config)
        self.risk_threshold = config.get('risk_threshold', 0.7)
        self.auto_close_threshold = config.get('auto_close_threshold', 0.3)
    
    async def execute(self, state: AlertInvestigationState) -> Dict[str, Any]:
        alert_id = state.alert_id
        print(f"[{self.agent_name}] Starting final risk assessment for alert {alert_id}.")

        # --- DEBUG: show which agent outputs we actually have ---
        print(f"[{self.agent_name}] Debug: agent_outputs keys = {list(state.agent_outputs.keys())}")

        # 1) Pull in context, patterns, explanation
        context     = state.context_data.get("alert_basic", {})
        # the workflow uses the key "pattern" for PatternRecognitionAgent
        patterns = state.agent_outputs.get("PatternRecognitionAgent", {})
        print(f"[{self.agent_name}] Debug: received patterns = {patterns!r}")

        explanation = state.agent_outputs.get("explanation", {})

        # 2) Compute risk assessment & decision
        risk_assessment = self._perform_comprehensive_risk_assessment(
            context, patterns, explanation, state
        )
        final_decision = self._make_final_decision(risk_assessment, state)

        # 3) Log the judgment
        self.log_judgement(
            alert_id=alert_id,
            action=final_decision["action"],
            confidence=risk_assessment["final_confidence"],
            rationale=risk_assessment,
            loop_iteration=state.loop_count
        )

        print(
            f"[{self.agent_name}] Final decision for alert {alert_id}: "
            f"{final_decision['action']} (Confidence: {risk_assessment['final_confidence']:.2f})"
        )

        # 4) Build the payload we’ll return to the orchestrator
        result: Dict[str, Any] = {
            "agent_outputs": { self.agent_name: risk_assessment },
            "final_decision": final_decision["action"],
            "outcome_type": final_decision["outcome_type"],
            "is_suspicious": final_decision["is_suspicious"],
            "investigation_summary": final_decision["summary"],
            "confidence_score": risk_assessment["final_confidence"],
            "risk_factors": risk_assessment.get("risk_factors", []),
            "loop_count": state.loop_count,
            # you can carry ingestion’s queries_executed here if you like
            "queries_executed": state.context_data.get("queries_executed", []),
        }

        # 5) If we still need another loop, do *not* save outcome yet
        if final_decision["action"] == "INVESTIGATE_FURTHER" and state.loop_count < state.max_loops:
            print(f"[{self.agent_name}] INVESTIGATE_FURTHER → looping back to ingestion.")
            result["context_data"] = { "need_deeper_analysis": True }
            result["loop_count"]    = state.loop_count + 1
            result["success"]       = False
            return result

        # 6) We’re truly done — ensure is_suspicious is boolean, then persist
        if result["is_suspicious"] is None:
            result["is_suspicious"] = False
        self._save_investigation_outcome(alert_id, final_decision, risk_assessment)

        print(f"[{self.agent_name}] Investigation complete for alert {alert_id}.")
        result["success"] = True
        return result



    
    def _perform_comprehensive_risk_assessment(self, context: Dict[str, Any], patterns: Dict[str, Any],
                                               explanation: Dict[str, Any], state: AlertInvestigationState) -> Dict[str, Any]:
        """Combine all agent outputs to determine a final risk score and level."""  
        base_risk_score = patterns.get('overall_confidence', 0.0)
        risk_factors = state.risk_factors

        alert_type = context.get('alert_type', '')
        type_risk_multiplier = {
            'HighValue': 1.2, 'FailedLoginTransfer': 1.3, 'Structuring': 1.4,
            'HighRiskLocation': 1.3, 'Velocity': 1.1, 'NewPayee': 1.0,
            'GeoMismatch': 1.1, 'CrossChannel': 0.9
        }.get(alert_type, 1.0)

        evidence_quality = len(state.evidence_collected) / 10.0
        evidence_adjustment = min(0.2, evidence_quality * 0.1)
        
        fp_adjustment = 0.1 if alert_type in ['CrossChannel', 'GeoMismatch'] else 0.0
        
        adjusted_risk = base_risk_score * type_risk_multiplier + evidence_adjustment + fp_adjustment
        final_confidence = min(0.95, max(0.05, adjusted_risk))

        if final_confidence >= 0.8:
            risk_level = 'HIGH'
        elif final_confidence >= 0.5:
            risk_level = 'MEDIUM'
        else:
            risk_level = 'LOW'
        
        return {
            'base_risk_score': base_risk_score, 'type_risk_multiplier': type_risk_multiplier,
            'evidence_adjustment': evidence_adjustment, 'fp_adjustment': fp_adjustment,
            'final_confidence': final_confidence, 'risk_level': risk_level,
            'risk_factors': risk_factors, 'total_evidence_points': len(state.evidence_collected),
            'investigation_loops': state.loop_count,
            'key_indicators': self._extract_key_indicators(patterns, explanation)
        }

    def _make_final_decision(self, risk_assessment: Dict[str, Any], state: AlertInvestigationState) -> Dict[str, Any]:
        """Make a final action decision based on risk assessment.""" 
        confidence = risk_assessment['final_confidence']
        risk_level = risk_assessment['risk_level']
        
        action, outcome_type, is_suspicious, summary = None, None, None, None

        if confidence >= self.risk_threshold:
            action = 'ESCALATE'
            outcome_type = OutcomeType.TRUE_POSITIVE
            is_suspicious = True
            summary = f"HIGH RISK: Confidence {confidence:.2f}. Multiple risk factors detected."
        elif confidence <= self.auto_close_threshold:
            action = 'AUTO_CLOSE'
            outcome_type = OutcomeType.FALSE_POSITIVE
            is_suspicious = False
            summary = f"LOW RISK: Confidence {confidence:.2f}. Likely false positive."
        else:
            if state.loop_count >= state.max_loops:
                action = 'HUMAN_REVIEW'
                outcome_type = OutcomeType.UNDER_INVESTIGATION
                is_suspicious = True
                summary = f"MEDIUM RISK: Confidence {confidence:.2f}. Requires human judgment after max loops."
            else:
                action = 'INVESTIGATE_FURTHER'
                outcome_type = OutcomeType.UNDER_INVESTIGATION
                is_suspicious = None
                summary = f"MEDIUM RISK: Confidence {confidence:.2f}. Need more investigation."

        return {'action': action, 'outcome_type': outcome_type, 'is_suspicious': is_suspicious,
                'summary': summary, 'confidence': confidence, 'risk_level': risk_level}

    def _extract_key_indicators(self, patterns: Dict[str, Any], explanation: Dict[str, Any]) -> List[str]:
        """Extract key risk indicators for reporting and audit trail.""" 
        indicators = []
        if isinstance(patterns, dict):
            for key, value in patterns.items():
                if isinstance(value, dict) and value.get('triggered'):
                    indicators.append(key)
        
        if isinstance(explanation, dict) and 'rationale' in explanation:
            rationale = explanation['rationale']
            if isinstance(rationale, dict) and 'key_points' in rationale:
                indicators.extend(rationale['key_points'][:3])
        return indicators[:5]

    def _save_investigation_outcome(self, alert_id: str, decision: Dict[str, Any], risk_assessment: Dict[str, Any]):
        """Save the final investigation outcome to the database.""" 
        outcome = {
            'outcome_id': str(uuid.uuid4()), 'alert_id': alert_id, 'final_outcome': decision['action'],
            'is_suspicious': decision.get('is_suspicious', False), 'confidence_score': risk_assessment['final_confidence'],
            'investigation_summary': decision['summary'], 'human_verified': False,
            'timestamp': datetime.now().isoformat()
        }
        with self.db.get_connection() as conn:
            conn.execute("""
            INSERT INTO investigation_outcomes
            (outcome_id, alert_id, final_outcome, is_suspicious, confidence_score, investigation_summary, human_verified, timestamp)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            """, (outcome['outcome_id'], outcome['alert_id'], outcome['final_outcome'],
                  outcome['is_suspicious'], outcome['confidence_score'], outcome['investigation_summary'],
                  outcome['human_verified'], outcome['timestamp']))
            conn.commit()